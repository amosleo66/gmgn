"""
GMGN API çˆ¬è™«ï¼ˆè°ƒè¯•ç‰ˆæœ¬ï¼‰- æ˜¾ç¤ºæ‰€æœ‰ API è¯·æ±‚
å¸®åŠ©æ‰¾åˆ°æ­£ç¡®çš„ç›®æ ‡ API URL
"""
import asyncio
import json
from pathlib import Path
from playwright.async_api import async_playwright, Response
from datetime import datetime

# å°è¯•åŠ è½½é…ç½®æ–‡ä»¶
try:
    from config import PROXY, HEADLESS, OUTPUT_FILE
except ImportError:
    PROXY = None
    HEADLESS = False
    OUTPUT_FILE = "gmgn_users_dedup.json"

class GmgnCrawlerDebug:
    def __init__(self, proxy=PROXY):
        self.proxy = proxy
        self.api_requests = []  # è®°å½•æ‰€æœ‰ API è¯·æ±‚

    async def handle_response(self, response: Response):
        """å¤„ç†å“åº”æ•°æ® - è°ƒè¯•æ¨¡å¼"""
        try:
            url = response.url

            # åªæ˜¾ç¤º gmgn.ai çš„ API è¯·æ±‚
            if 'gmgn.ai' in url and '/api/' in url:
                status = response.status
                method = response.request.method

                # è®°å½•è¯·æ±‚ä¿¡æ¯
                request_info = {
                    'time': datetime.now().strftime('%H:%M:%S'),
                    'method': method,
                    'url': url,
                    'status': status
                }

                # æ£€æŸ¥æ˜¯å¦æ˜¯ç”¨æˆ·æœç´¢ API
                is_target = '/twitter/user/search' in url

                print(f"\n[{request_info['time']}] {'ğŸ¯' if is_target else 'ğŸ“¡'} {method} {status}")
                print(f"URL: {url}")

                # å¦‚æœæ˜¯ç›®æ ‡ APIï¼Œå°è¯•è§£æå“åº”
                if is_target and status == 200:
                    try:
                        data = await response.json()
                        if data.get('code') == 0 and 'data' in data and 'users' in data['data']:
                            users = data['data']['users']
                            print(f"âœ… ç›®æ ‡ APIï¼è·å–åˆ° {len(users)} ä¸ªç”¨æˆ·")

                            # æ˜¾ç¤ºå‰3ä¸ªç”¨æˆ·
                            for i, user in enumerate(users[:3], 1):
                                print(f"   {i}. @{user.get('handle')} ({user.get('followers')} ç²‰ä¸)")
                        else:
                            print(f"âš ï¸  å“åº”æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ")
                    except Exception as e:
                        print(f"âŒ è§£æå¤±è´¥: {e}")

                self.api_requests.append(request_info)

        except Exception as e:
            pass

    async def start_browser(self):
        """å¯åŠ¨æµè§ˆå™¨å¹¶å¼€å§‹ç›‘æ§"""
        async with async_playwright() as p:
            # æµè§ˆå™¨å¯åŠ¨å‚æ•°
            launch_args = {
                'headless': False,
                'args': [
                    '--disable-blink-features=AutomationControlled',
                    '--no-sandbox',
                    '--disable-dev-shm-usage',
                ]
            }

            # è®¾ç½®ä»£ç†
            context_args = {
                'viewport': {'width': 1920, 'height': 1080},
                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36'
            }

            if self.proxy:
                context_args['proxy'] = {'server': self.proxy}

            print("\nğŸš€ æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
            browser = await p.chromium.launch(**launch_args)
            context = await browser.new_context(**context_args)
            page = await context.new_page()

            # ç›‘å¬æ‰€æœ‰å“åº”
            page.on('response', lambda response: asyncio.create_task(self.handle_response(response)))

            print("\n" + "=" * 70)
            print("ğŸ› GMGN API çˆ¬è™« - è°ƒè¯•æ¨¡å¼")
            print("=" * 70)
            print("ğŸ“‹ åŠŸèƒ½: æ˜¾ç¤ºæ‰€æœ‰ gmgn.ai çš„ API è¯·æ±‚")
            print("ğŸ¯ ç›®æ ‡: /twitter/user/search")
            if self.proxy:
                print(f"ğŸ” ä»£ç†: {self.proxy}")
            else:
                print("ğŸŒ ä»£ç†: æ— ï¼ˆç›´è¿ï¼‰")

            print("\n" + "!" * 70)
            print("ğŸ“– ä½¿ç”¨è¯´æ˜ï¼š")
            print("  1ï¸âƒ£  æµè§ˆå™¨çª—å£å·²æ‰“å¼€")
            print("  2ï¸âƒ£  æ‰‹åŠ¨è®¿é—®: https://gmgn.ai/")
            print("  3ï¸âƒ£  åœ¨é¡µé¢ä¸Šè¿›è¡Œä»¥ä¸‹æ“ä½œï¼š")
            print("     - ç‚¹å‡»ã€Œç”¨æˆ·ã€æˆ–ã€ŒUserã€æ ‡ç­¾")
            print("     - æœç´¢ç”¨æˆ·")
            print("     - æµè§ˆç”¨æˆ·åˆ—è¡¨")
            print("     - åˆ‡æ¢ç”¨æˆ·åˆ†ç±»æ ‡ç­¾")
            print("  4ï¸âƒ£  è§‚å¯Ÿç»ˆç«¯è¾“å‡ºï¼Œæ‰¾åˆ°ç›®æ ‡ API")
            print("  5ï¸âƒ£  æŒ‰ Ctrl+C åœæ­¢")
            print("!" * 70 + "\n")

            try:
                await page.goto('about:blank', timeout=5000)
                print("âœ… æµè§ˆå™¨å·²å°±ç»ª")
                print("ğŸ‘‰ è¯·åœ¨æµè§ˆå™¨ä¸­è®¿é—®: https://gmgn.ai/")
                print("\nâ³ ç›‘å¬ä¸­...\n")
            except Exception as e:
                print(f"âš ï¸  {e}")

            try:
                while True:
                    await asyncio.sleep(1)
            except KeyboardInterrupt:
                print("\n\n" + "=" * 70)
                print("ğŸ›‘ åœæ­¢è°ƒè¯•")
                print("=" * 70)
                print(f"ğŸ“Š æ•è·åˆ° {len(self.api_requests)} ä¸ª API è¯·æ±‚")

                # ç»Ÿè®¡ API URL
                if self.api_requests:
                    print("\nğŸ“‹ API è¯·æ±‚æ±‡æ€»:")
                    url_counts = {}
                    for req in self.api_requests:
                        # ç®€åŒ– URLï¼ˆå»æ‰æŸ¥è¯¢å‚æ•°ï¼‰
                        base_url = req['url'].split('?')[0]
                        url_counts[base_url] = url_counts.get(base_url, 0) + 1

                    for url, count in sorted(url_counts.items(), key=lambda x: x[1], reverse=True):
                        print(f"  [{count:2d}x] {url}")

                    # æ£€æŸ¥æ˜¯å¦æœ‰ç›®æ ‡ API
                    target_found = any('/twitter/user/search' in req['url'] for req in self.api_requests)
                    if target_found:
                        print("\nâœ… å·²æ•è·åˆ°ç›®æ ‡ APIï¼")
                        print("ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨æ­£å¼ç‰ˆæœ¬:")
                        print("   python gmgn_crawler_v2.py")
                    else:
                        print("\nâš ï¸  æœªæ•è·åˆ°ç›®æ ‡ API")
                        print("ğŸ’¡ å»ºè®®:")
                        print("  1. ç¡®ä¿åœ¨é¡µé¢ä¸Šç‚¹å‡»äº†ã€Œç”¨æˆ·ã€æ ‡ç­¾")
                        print("  2. å°è¯•æœç´¢ç”¨æˆ·æˆ–æµè§ˆç”¨æˆ·åˆ—è¡¨")
                        print("  3. æŸ¥çœ‹ä¸Šé¢çš„ API åˆ—è¡¨ï¼Œæ‰¾åˆ°ç”¨æˆ·ç›¸å…³çš„æ¥å£")
            finally:
                await browser.close()

async def main():
    import sys

    proxy = PROXY
    if '--proxy' in sys.argv:
        idx = sys.argv.index('--proxy')
        if idx + 1 < len(sys.argv):
            proxy = sys.argv[idx + 1]

    crawler = GmgnCrawlerDebug(proxy=proxy)
    await crawler.start_browser()

if __name__ == '__main__':
    asyncio.run(main())
"""
GMGN API çˆ¬è™«ï¼ˆé«˜çº§ç‰ˆæœ¬ v2ï¼‰- ä½¿ç”¨å“åº”ç›‘å¬è€Œéè¯·æ±‚æ‹¦æˆª
ä½¿ç”¨ Playwright ç›‘å¬æµè§ˆå™¨å“åº”ï¼Œè‡ªåŠ¨å»é‡ç”¨æˆ·
æ”¯æŒä»£ç†ã€æ›´ç¨³å®šã€ä¸ä¼šå¡é¡¿
"""
import asyncio
import json
import sys
from pathlib import Path
from playwright.async_api import async_playwright, Response
from datetime import datetime

# å°è¯•åŠ è½½é…ç½®æ–‡ä»¶
try:
    from config import PROXY, HEADLESS, OUTPUT_FILE
except ImportError:
    print("æœªæ‰¾åˆ° config.pyï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    PROXY = None
    HEADLESS = False
    OUTPUT_FILE = "gmgn_users_dedup.json"

class GmgnCrawlerV2:
    def __init__(self, output_file=OUTPUT_FILE, proxy=PROXY):
        self.output_file = Path(output_file)
        self.users_dict = {}  # ä½¿ç”¨å­—å…¸å­˜å‚¨ï¼Œkey ä¸º user_idï¼Œè‡ªåŠ¨å»é‡
        self.target_url_prefix = 'https://gmgn.ai/vas/api/v1/twitter/user/search'
        self.request_count = 0
        self.proxy = proxy

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼ŒåŠ è½½å·²æœ‰æ•°æ®
        self.load_existing_data()

    def load_existing_data(self):
        """åŠ è½½å·²å­˜åœ¨çš„æ•°æ®æ–‡ä»¶"""
        if self.output_file.exists():
            try:
                with open(self.output_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if 'users' in data:
                        for user in data['users']:
                            self.users_dict[user['user_id']] = user
                        print(f"âœ“ åŠ è½½å·²æœ‰æ•°æ®: {len(self.users_dict)} ä¸ªç”¨æˆ·")
            except Exception as e:
                print(f"âš  åŠ è½½å·²æœ‰æ•°æ®å¤±è´¥: {e}")

    async def handle_response(self, response: Response):
        """å¤„ç†å“åº”æ•°æ®"""
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡ API
            if response.url.startswith(self.target_url_prefix):
                # åªå¤„ç†æˆåŠŸçš„å“åº”
                if response.status == 200:
                    try:
                        # è·å–å“åº”æ•°æ®
                        data = await response.json()

                        # æå– users æ•°æ®
                        if data.get('code') == 0 and 'data' in data and 'users' in data['data']:
                            users = data['data']['users']

                            # ç»Ÿè®¡æ–°å¢ç”¨æˆ·
                            new_users = 0
                            for user in users:
                                user_id = user['user_id']
                                if user_id not in self.users_dict:
                                    new_users += 1
                                self.users_dict[user_id] = user  # æ›´æ–°æˆ–æ·»åŠ ç”¨æˆ·

                            self.request_count += 1

                            print(f"\n[{datetime.now().strftime('%H:%M:%S')}] âœ… æ•è·åˆ°ç¬¬ {self.request_count} ä¸ªè¯·æ±‚")
                            print(f"ğŸ“Š æœ¬æ¬¡è·å–: {len(users)} ä¸ªç”¨æˆ·ï¼Œæ–°å¢: {new_users} ä¸ª")
                            print(f"ğŸ“ˆ ç´¯è®¡ç”¨æˆ·æ•°ï¼ˆå»é‡åï¼‰: {len(self.users_dict)}")

                            # å®æ—¶ä¿å­˜åˆ°æ–‡ä»¶
                            if new_users > 0:
                                self.save_data()

                    except Exception as e:
                        print(f"âŒ è§£æå“åº”æ—¶å‡ºé”™: {e}")

        except Exception as e:
            # å¿½ç•¥é”™è¯¯ï¼Œç»§ç»­ç›‘å¬
            pass

    def save_data(self):
        """ä¿å­˜æ•°æ®åˆ° JSON æ–‡ä»¶"""
        users_list = list(self.users_dict.values())
        # æŒ‰ç…§ followers æ•°é‡æ’åº
        users_list.sort(key=lambda x: x.get('followers', 0), reverse=True)

        output_data = {
            'total_users': len(users_list),
            'last_updated': datetime.now().isoformat(),
            'users': users_list
        }

        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {self.output_file.absolute()}")

    async def start_browser(self, headless=HEADLESS):
        """å¯åŠ¨æµè§ˆå™¨å¹¶å¼€å§‹ç›‘æ§"""
        async with async_playwright() as p:
            # æµè§ˆå™¨å¯åŠ¨å‚æ•°
            launch_args = {
                'headless': headless,
                'args': [
                    '--disable-blink-features=AutomationControlled',
                    '--no-sandbox',
                    '--disable-dev-shm-usage',
                ]
            }

            # å¦‚æœæä¾›äº†ä»£ç†ï¼Œæ·»åŠ ä»£ç†å‚æ•°
            context_args = {
                'viewport': {'width': 1920, 'height': 1080},
                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36'
            }

            if self.proxy:
                context_args['proxy'] = {'server': self.proxy}

            # å¯åŠ¨æµè§ˆå™¨
            print("\nğŸš€ æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
            browser = await p.chromium.launch(**launch_args)

            # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼ˆå¸¦ä»£ç†é…ç½®ï¼‰
            context = await browser.new_context(**context_args)
            page = await context.new_page()

            # ç›‘å¬å“åº”äº‹ä»¶ï¼ˆä¸æ‹¦æˆªè¯·æ±‚ï¼‰
            page.on('response', lambda response: asyncio.create_task(self.handle_response(response)))

            print("\n" + "=" * 70)
            print("ğŸ¯ GMGN API çˆ¬è™«å·²å¯åŠ¨ï¼ˆé«˜çº§ç‰ˆæœ¬ v2 - å“åº”ç›‘å¬æ¨¡å¼ï¼‰")
            print("=" * 70)
            print(f"ğŸ“¡ ç›®æ ‡ API: {self.target_url_prefix}")
            print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {self.output_file.absolute()}")
            print(f"ğŸ“Š å·²æœ‰ç”¨æˆ·: {len(self.users_dict)}")
            if self.proxy:
                print(f"ğŸ” ä»£ç†è®¾ç½®: {self.proxy}")
            else:
                print(f"ğŸŒ ä»£ç†è®¾ç½®: æ— ï¼ˆç›´è¿ï¼‰")

            print("\n" + "!" * 70)
            print("ğŸ“‹ ä½¿ç”¨è¯´æ˜ï¼š")
            print("  1ï¸âƒ£  æµè§ˆå™¨çª—å£å·²æ‰“å¼€")
            print("  2ï¸âƒ£  è¯·æ‰‹åŠ¨åœ¨æµè§ˆå™¨åœ°å€æ è¾“å…¥: https://gmgn.ai/")
            print("  3ï¸âƒ£  åœ¨é¡µé¢ä¸­æœç´¢ã€æµè§ˆç”¨æˆ·")
            print("  4ï¸âƒ£  çˆ¬è™«ä¼šè‡ªåŠ¨æ•è· API å“åº”å¹¶ä¿å­˜æ•°æ®")
            print("  5ï¸âƒ£  æŒ‰ Ctrl+C åœæ­¢çˆ¬è™«")
            print("\nğŸ’¡ æç¤ºï¼šä½¿ç”¨å“åº”ç›‘å¬æ¨¡å¼ï¼Œé¡µé¢åŠ è½½æ›´æµç•…ï¼")
            print("!" * 70 + "\n")

            # æ‰“å¼€ç©ºç™½é¡µï¼Œè®©ç”¨æˆ·æ‰‹åŠ¨è®¿é—® gmgn.ai
            try:
                await page.goto('about:blank', timeout=5000)
                print("âœ… æµè§ˆå™¨å·²å°±ç»ª")
                print("ğŸ‘‰ è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨è®¿é—®: https://gmgn.ai/\n")
                print("â³ ç­‰å¾…æ•è·æ•°æ®...\n")
            except Exception as e:
                print(f"âš ï¸  é¡µé¢åŠ è½½è­¦å‘Š: {e}")
                print("ğŸ‘‰ è¯·ç»§ç»­åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨è®¿é—®: https://gmgn.ai/\n")

            try:
                # ä¿æŒæµè§ˆå™¨æ‰“å¼€ï¼Œç›´åˆ°ç”¨æˆ·æŒ‰ Ctrl+C
                while True:
                    await asyncio.sleep(1)
            except KeyboardInterrupt:
                print("\n\n" + "=" * 70)
                print("ğŸ›‘ æ­£åœ¨åœæ­¢çˆ¬è™«...")
                print("=" * 70)
                print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
                print(f"   - æ•è·è¯·æ±‚æ•°: {self.request_count}")
                print(f"   - æ”¶é›†ç”¨æˆ·æ•°: {len(self.users_dict)}")
                if len(self.users_dict) > 0:
                    self.save_data()
                    print(f"\nâœ… çˆ¬è™«å·²æˆåŠŸåœæ­¢")
                else:
                    print(f"\nâš ï¸  æœªæ•è·åˆ°ä»»ä½•æ•°æ®")
            finally:
                await browser.close()

async def main():
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    proxy = PROXY
    output_file = OUTPUT_FILE

    if len(sys.argv) > 1:
        if '--proxy' in sys.argv:
            idx = sys.argv.index('--proxy')
            if idx + 1 < len(sys.argv):
                proxy = sys.argv[idx + 1]

        if '--output' in sys.argv:
            idx = sys.argv.index('--output')
            if idx + 1 < len(sys.argv):
                output_file = sys.argv[idx + 1]

        if '--help' in sys.argv or '-h' in sys.argv:
            print("GMGN API çˆ¬è™« - é«˜çº§ç‰ˆæœ¬ v2")
            print("\nç”¨æ³•:")
            print("  python gmgn_crawler_v2.py [é€‰é¡¹]")
            print("\né€‰é¡¹:")
            print("  --proxy <ä»£ç†åœ°å€>    è®¾ç½®ä»£ç†æœåŠ¡å™¨")
            print("                       ä¾‹å¦‚: --proxy http://127.0.0.1:7890")
            print("  --output <æ–‡ä»¶å>     è®¾ç½®è¾“å‡ºæ–‡ä»¶å")
            print("                       ä¾‹å¦‚: --output my_data.json")
            print("  --help, -h           æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
            print("\nç¤ºä¾‹:")
            print("  python gmgn_crawler_v2.py --proxy http://127.0.0.1:7890")
            print("  python gmgn_crawler_v2.py --output my_users.json")
            print("\né…ç½®æ–‡ä»¶:")
            print("  å¯ä»¥ç¼–è¾‘ config.py æ–‡ä»¶æ¥è®¾ç½®é»˜è®¤é…ç½®")
            print("\næ–°ç‰¹æ€§:")
            print("  âœ… ä½¿ç”¨å“åº”ç›‘å¬è€Œéè¯·æ±‚æ‹¦æˆª")
            print("  âœ… é¡µé¢åŠ è½½æ›´æµç•…ï¼Œä¸ä¼šå¡é¡¿")
            print("  âœ… ä»£ç†é…ç½®æ›´å¯é ")
            return

    crawler = GmgnCrawlerV2(output_file=output_file, proxy=proxy)
    await crawler.start_browser(headless=HEADLESS)

if __name__ == '__main__':
    asyncio.run(main())